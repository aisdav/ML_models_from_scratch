# ğŸ§  ML Models From Scratch

This repository contains implementations of classical Machine Learning algorithms **from scratch**, using only **NumPy** and basic Python libraries.

The goal of this project is **deep understanding**, not performance or library usage.

---

## ğŸ¯ Motivation

Many ML practitioners rely heavily on high-level libraries without fully understanding:

* how optimization works
* what model parameters actually control
* why models fail or overfit

This repository was created to:

* demystify core ML algorithms
* build intuition behind training and inference
* strengthen algorithmic thinking for real-world ML problems and competitions

---

## ğŸ› ï¸ Implemented Algorithms

### ğŸ”¹ Linear Models

* Linear Regression
* Normal Equation
* Gradient Descent
* Logistic Regression
* Sigmoid function
* Binary Cross-Entropy Loss

### ğŸ”¹ Probabilistic Models

* Naive Bayes (Gaussian)
* Prior / Likelihood / Posterior

### ğŸ”¹ Distance-based Models

* k-Nearest Neighbors (kNN)

### ğŸ”¹ Tree-based Models and Ensembles

* Decision Tree
* Gini Impurity / Entropy
* Random Forest
* Gradient Boosting (simplified implementation)

### ğŸ”¹ Margin-based Models

* Support Vector Machine (SVM)
* Hard & Soft Margin
* Hinge Loss
* Kernel intuition (linear / polynomial)

### ğŸ”¹ Dimensionality Reduction

* Principal Component Analysis (PCA)
* Covariance matrix
* Eigen decomposition
* Explained variance ratio

---

## ğŸ“Š Model Evaluation

Implemented evaluation techniques:

* Train / Validation / Test split
* Cross-validation

Metrics:

* Accuracy
* Precision / Recall
* F1-score
* ROC AUC (simplified)

---

## âš™ï¸ Optimization & Regularization

* Gradient Descent
* Learning rate analysis
* L1 / L2 Regularization
* Biasâ€“Variance tradeoff

---

## ğŸ§ª Experiments

Each algorithm includes:

* synthetic data tests
* real dataset experiments
* visualization of decision boundaries (where applicable)
* comparison with `sklearn` implementation for validation

---

## ğŸ“Œ Tech Stack

* Python
* NumPy
* Matplotlib
* Scikit-learn (for comparison only)

---

## ğŸš€ Who Is This For?

* Students learning Machine Learning
* Data Scientists preparing for interviews
* Participants of ML competitions / hackathons
* Anyone who wants to **really understand** how ML algorithms work

---

## ğŸ“ˆ Future Work

* Neural Networks from scratch
* Advanced optimization techniques (Adam, RMSProp)
* Advanced boosting algorithms (XGBoost-style logic)

---

## âœ¨ Author

Built with a focus on fundamentals, clarity, and long-term mastery in Machine Learning. 
Davletkan Aisultan Future ML engineer
